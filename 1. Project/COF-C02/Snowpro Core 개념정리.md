# SnowPro Core (COF-C02) 認定試験マスタープラン：出題比重ベースの深層分析ガイド

## 1.0 はじめに：SnowPro Core 認定試験と本ガイドの概要

SnowPro Core Certification(COF-C02)は、Snowflakeデータクラウドの実装と移行に必要な核心的な専門知識と技術を検証する試験である。1 この資格を取得することにより、受験者はSnowflakeデータクラウドに対する徹底的な理解を基に、ビジネス目標達成のための安全で拡張可能なソリューションを開発および管理するために必要な知識を備えることになる。1 試験はSnowflakeプラットフォームを最低6ヶ月以上使用した経験のある受験者に推奨され、基本的なANSI SQL構文の知識を前提とする。1

本レポートは、Snowflakeが公式に提供するSnowPro Core試験学習ガイド(COF-C02)に基づき、試験に出題される主要な概念を、出題比重の高い順に深層的に分析し、整理することを目的とする。試験は合計6つの主題ドメインで構成され、各ドメインの重みが異なるため、これを考慮した学習計画の策定が非常に重要である。1 以下の表は、試験の主題ドメインと出題比重を要約したものである。

本ガイドの核心戦略は、単なる概念の羅列を超え、各概念がSnowflakeのユニークなアーキテクチャとどのように有機的に連携して動作するかを深く分析することである。出題比重の高いドメインから学習し、核心概念を優先的にマスターすることで、受験者は試験準備の効率を最大化できるだろう。

## 2.0 ドメイン 1.0: Snowflake データクラウドの機能とアーキテクチャ (25%)

このドメインは、Snowflakeの根本的な動作原理を扱う最も重要な領域である。Snowflakeの革新的なアーキテクチャ、ストレージメカニズム、そして主要なインターフェースとオブジェクトに対する包括的な理解は、試験成功の基礎となる。

### 2.1 Snowflakeの核心アーキテクチャ（分離型3層）

Snowflakeの独占的なクラウドベースのアーキテクチャは、ストレージ、コンピューティング、クラウドサービスの3つの層が独立して分離され、動作し、管理されることが特徴である。このような設計は、優れた柔軟性、パフォーマンス、そしてコスト効率を可能にする。3 各層は固有の役割を果たしながらも、緊密に相互作用し、円滑なデータウェアハウジング体験を提供する。

#### 2.1.1 データベースストレージ層 (Database Storage Layer)

データベースストレージ層は、中央集権的なデータリポジトリの役割を果たす。Snowflakeがサポートするすべてのデータ（構造化、半構造化など）はこの層に保存され、マイクロパーティション（Micro-Partitions）という圧縮された不変（immutable）の単位で管理される。2 この層はクラウド環境で拡張可能なストレージを活用し、データは複数のクラウドにまたがって冗長に保存され、耐久性と可用性を保証する。データはSnowflakeが管理するリモートストレージに存在し、これはすべてのコンピューティングリソースと分離されているため、独立したスケーリングが可能である。

#### 2.1.2 クエリ処理層 (Query Processing Layer)

クエリ処理層は、仮想ウェアハウス（Virtual Warehouse）を通じてクエリ実行を担当するコンピューティングリソースである。各ウェアハウスは1つ以上のクラスタで構成され、これはクエリ処理に必要なCPU、メモリ、SSDキャッシュなどを抽象化した概念である。Snowflakeはワークロードに応じて独立したウェアハウスを生成し、特定のクエリのパフォーマンスが他のクエリに影響を与えないように隔離する。このような柔軟なコンピューティングリソースの分離は、多様なワークロードを同時に効率的に処理することを可能にする。

#### 2.1.3 クラウドサービス層 (Cloud Services Layer)

クラウドサービス層は、Snowflakeシステム全体の頭脳の役割を果たす最も重要な構成要素である。2 この層は、クエリの解析と最適化、認証とセキュリティ、メタデータ管理、アクセス制御など、多様な核心サービスを担当する。2 特にこの層にはグローバル結果キャッシュ（Global Result Cache）が含まれており、同じクエリが再度実行された場合、コンピューティングリソースを使用せずに即座に結果を返すことで、クエリのパフォーマンスを大幅に向上させる。3

### 2.2 Snowflakeのストレージとマイクロパーティションの概念

#### 2.2.1 マイクロパーティション (Micro-Partitions)

マイクロパーティションは、Snowflakeの根本的なデータ保存単位である。テーブルのデータはSnowflakeにロードされる際に、自動的に50MBから500MBの間の非圧縮の不変（immutable）単位に分割される。

このパーティションは列ごとにソートされて保存され、各列の値の範囲、ユニークな値の数、そして追加の最適化属性など、重要なメタデータを含む。

データが一度マイクロパーティションに保存されると変更できず、すべての変更（DML）は新しいマイクロパーティションを生成することによって処理される。

#### 2.2.2 プルーニング (Pruning)

マイクロパーティションのメタデータを活用してクエリ実行を最適化する技法が、プルーニング（pruning）である。
クエリオプティマイザはWHERE句のフィルタ条件を分析し、マイクロパーティションのメタデータ（例：値の範囲）を活用して、クエリ結果と関連のないパーティションをスキャン対象から除外する。

このプロセスを通じて、スキャン範囲を画期的に減らし、クエリのパフォーマンスを劇的に向上させることができる。

### 2.3 データクラスタリング (Data Clustering)

データクラスタリングは、関連する行を物理的に同じマイクロパーティションにグループ化する技術であり、プルーニング（pruning）の効率を最大化するために不可欠である。

テーブルにクラスタリングキーを定義してこの作業を行い、クラスタリングキーは1つ以上の列または式で構成できる。

#### 2.3.1 クラスタリングキーの役割と選択戦略

クラスタリングキーは、テーブル作成時（CREATE TABLE）または後で（ALTER TABLE）定義できる。

クエリのフィルタリングやジョインに頻繁に使用される列が良い候補となり、特にユニークな値の数が多く（高いカーディナリティ）、効果的なプルーニングを可能にする列が適している。

一般的に3〜4個以下の列を指定することが、コスト対効果が高いと推奨されている。クラスタリングキーは、テーブルのデータ分布とクエリパターンを慎重に分析して選択する必要がある。

#### 2.3.2 自動クラスタリング

Snowflakeは、クラスタリングキーが定義されたテーブルのデータ変更が発生すると、バックグラウンドで自動的に再構成作業を行い、最適なクラスタリング状態を維持する。このようなメンテナンス作業は追加のコストを発生させるが、クエリのパフォーマンスを継続的に最適化することに貢献する。

SHOW TABLESコマンドを通じてテーブルの自動クラスタリング状態を確認でき、automatic_clustering_historyビューを通じてクラスタリングコストを追跡できる。

### 2.4 主要なツールとインターフェース

Snowflakeは、多様なワークロードとユーザーロールをサポートするために、いくつかのツールとインターフェースを提供する。

Snowsight: Snowflakeの主要なWebインターフェースで、強力なSQLエディタ（Worksheets）、データ可視化（Charts）、ダッシュボード、およびStreamlit/Native App開発機能を提供する。12 クエリ履歴の監視、ロール管理、コスト管理など、総合的な機能をサポートし、ユーザーの生産性を向上させる。12

SnowSQL: Snowflakeに接続するためのコマンドラインインターフェース（CLI）クライアントである。14 SQLクエリの実行、DDL/DML操作、大容量データのロードおよびアンロードなど、多様な管理作業を実行できる。15 特に、
PUTおよびGETコマンドを実行する主要な手段である。16

Snowpark: Python、Java、Scalaなど、SQL以外の言語でデータ処理およびモデリングコードを作成し、Snowflake内で実行できるようにするAPIライブラリである。18 これは
コードをデータに持ち込む（bring the code to the data）パラダイムを実装し、データ移動を最小限に抑え、パフォーマンスを最大化する。18

### 2.5 Snowflakeカタログとオブジェクト

Snowflakeのデータベース構造は、アカウント（Account）を最上位のコンテナとし、その下にデータベース（Database）、スキーマ（Schema）、そしてテーブル（Table）、ビュー（View）、ユーザー定義関数（UDF）などのオブジェクトが階層的に保存される方式で構成される。20 このような階層構造は、Snowflakeのロールベースのアクセス制御（RBAC）フレームワークと組み合わさり、オブジェクトに対する権限管理を効率的に実行できるようにする。20

データベース（Database）: スキーマと他のオブジェクトを含む最上位のコンテナである。

スキーマ（Schema）: データベース内のオブジェクトを論理的にグループ化するコンテナである。

テーブル（Table）: Snowflakeの基本的なデータ保存オブジェクトである。

ビュー（View）: 基本テーブルのデータに基づく論理的なテーブルである。

ユーザー定義関数（UDF）: SQLや他の言語でユーザー指定のロジックを実装し、再利用可能な関数を生成できる。

### 2.6 深層分析：アーキテクチャ原理の波及効果

Snowflakeの核心は、単にコンピューティングとストレージを分離することを超え、この分離型アーキテクチャがマイクロパーティションという不変のデータ単位を中心に、どのようにZero-Copy Cloning、Secure Data Sharing、Time Travelのような独占的な機能を生み出したかを理解することにある。

Zero-Copy Cloningは、物理的なデータブロックをコピーする代わりに、既存のマイクロパーティションに対するメタデータポインタのみを生成し、複製を即座に作成する。22 同様に、

Secure Data Sharingは、プロバイダーアカウントの元のデータへの参照のみを共有し、実際のデータは移動も複製もされない。23 また、

Time Travelは、データの変更または削除時にマイクロパーティションを即座に削除せず、一定期間保存するメタデータ管理方式を通じて実装される。24

これらすべての機能は、Snowflakeのストレージ層が「不変のマイクロパーティション」に基づいており、クラウドサービス層がこのパーティションの位置と状態を管理する「メタデータ」を担当するために可能である。したがって、分離型アーキテクチャは単にコスト効率を提供するだけでなく、データ複製のない高度な機能を生み出す核心的な技術的基盤である。試験は、このような機能の「原理」に対する理解を要求するだろう。

## 3.0 ドメイン 2.0: アカウントアクセスとセキュリティ (20%)

このドメインは、Snowflake環境でデータアクセスを安全かつ効率的に管理する方法を扱う。特に、ロールベースのアクセス制御（RBAC）とデータガバナンス機能に対する理解が重要である。

### 3.1 ロールベースのアクセス制御（RBAC）フレームワーク

Snowflakeは、ロールベースのアクセス制御（RBAC）を通じてセキュリティを管理する。25 このモデルは、権限（privilege）をユーザー（user）に直接付与する代わりに、ロール（role）に付与し、ロールをユーザーに割り当てる方式である。21 このアプローチは、権限管理を簡潔にし、大規模な組織で拡張が容易であるという利点がある。27

SnowflakeはRBACを基本として使用しながらも、オブジェクトの所有者がアクセス権限を制御するDAC（Discretionary Access Control）の特性を組み合わせたハイブリッドモデルを使用する。27 すべてのセキュリティ保護可能なオブジェクト（securable object）は単一のロールによって所有され、基本的にはオブジェクトを作成したロールが所有権を持つ。21

MANAGE GRANTS権限を持つロールやManaged Access Schemaを使用すると、所有者でない他のロールが権限を付与または取り消すことができ、柔軟な権限管理が可能になる。27

### 3.2 システム定義ロールとロール階層

Snowflakeは、多様な管理レベルをサポートするいくつかの組み込みシステムロールを提供する。20 これらのロールは削除または変更できず、特定の権限セットを持つ。28

ACCOUNTADMIN: アカウント内のすべてのオブジェクトに対するグローバルな制御権限を持つ最上位のロールである。SYSADMINとSECURITYADMINロールのすべての権限を含む。20

SYSADMIN: 仮想ウェアハウス、データベースなど、多様なオブジェクトを作成する役割を果たす。20

SECURITYADMIN: ユーザーとロールの管理を専門とし、グローバルにすべての権限付与を管理できる。20

USERADMIN: ユーザーとロールの管理のみを担当し、アカウント内のユーザーとロールを作成し、所有できる。20

PUBLIC: すべてのユーザーが基本的に持つロールである。28

Snowflakeの最も重要なセキュリティ概念の1つは、ロール階層（Role Hierarchy）である。28 あるロールが他のロールに付与されることで階層構造を形成し、下位ロールに付与されたすべての権限は上位ロールによって自動的に継承される。20 このような構造は、権限管理を簡素化し、最小権限の原則を適用するのに効果的である。27

### 3.3 データガバナンス機能

Snowflakeは、詳細なデータ保護と規制遵守のための多様なガバナンス機能を提供する。

Secure View: ビューの定義（基本テーブル、列など）を隠し、機密情報が公開されるのを防ぐ。29
Secure Viewは、データマスキング（masking）ポリシーや行アクセスポリシー（row access policy）と組み合わせて、ユーザーロールに応じてデータの特定の部分を隠したり、アクセスを制限したりできる。29
Secure Viewは、追加のセキュリティチェックにより、通常のビューよりもパフォーマンスが若干低下する可能性がある。29

オブジェクトタグ（Object Tagging）: データベース、スキーマ、テーブル、列など、多様なオブジェクトに「key-value」ペアのタグを付けて分類し、管理する機能である。31 タグは、データガバナンス、コスト監視、機密データ識別（
PII）などに活用される。31 上位オブジェクトに付与されたタグは、下位オブジェクトに継承されるタグの系譜（tag lineage）を持つ。32

Access History: Snowflakeオブジェクトに対する読み取り/書き込み操作を追跡する監査（auditing）機能である。これにより、誰がいつどのデータにアクセスしたかを把握し、セキュリティ脅威を検出し、規制遵守を保証できる。33

### 3.4 深層分析：複合的ガバナンス体制の構築

Snowflakeのセキュリティモデルは、単にRBACを実装するだけでなく、ロール階層、オブジェクトタグ、Secure Viewなどの高度な機能を組み合わせて、詳細で拡張可能なデータガバナンス体制を構築する。ロール階層は、権限の継承を通じて基本的な権限体系を構築し、管理の複雑さを軽減する。20 しかし、これだけではすべてのセキュリティ要件を満たすことは難しい。例えば、特定の列に含まれる個人識別情報（PII）は、ロールに関係なくアクセスを制限する必要がある場合がある。

このとき、オブジェクトタグを使用してPII列を識別し、このタグに基づいてSecure Viewやマスキングポリシーを自動的に適用して動的なセキュリティを実装できる。32 このように、Snowflakeのセキュリティ概念は独立した機能ではない。

ロール階層は基本的な権限体系を形成し、その上にオブジェクトタグでデータを分類し、Secure ViewやRow-level securityを通じて分類されたデータに対する詳細なアクセス制御を適用する相互補完的な関係を持つ。34 この複合的な体系に対する理解は、試験で高得点を得るために重要である。

## 4.0 ドメイン 5.0: データ変換 (20%)

このドメインは、Snowflakeの強力なデータ変換機能を扱う。特に、Snowflakeが半構造化データをどのように処理し、ストリームとタスクを活用してデータパイプラインをどのように自動化するかについての知識が重要である。

### 4.1 半構造化データの操作

Snowflakeは、JSON、XML、Parquet、Avroなどの半構造化データを変換プロセスなしで直接保存し、クエリできる独占的な機能を提供する。35 この機能の核心は、

VARIANTデータ型とFLATTEN関数である。

#### 4.1.1 VARIANTデータ型

VARIANTは、スキーマのない半構造化データを保存するために設計された柔軟なデータ型である。36 JSON、XMLのような階層的データを単一の列に保存でき、Snowflakeはデータをロードする際に自動的に解析して内部的に圧縮する。36

VARIANTを使用すると、データをリレーショナルテーブルに変換する複雑なETLプロセスを省略し、スキーマオンリード（schema-on-read）方式でクエリ時に構造を解釈して柔軟なデータ処理が可能になる。36

#### 4.1.2 FLATTEN関数

FLATTEN関数は、VARIANT、OBJECT、またはARRAY列に含まれるネストされた階層構造をリレーショナル構造の行に分解するテーブル関数である。37 この関数は、半構造化データをリレーショナルテーブルのように簡単にクエリし、分析できるように支援する。38

LATERAL FLATTENを使用すると、複数のネスト構造を一度にフラット化でき、複雑なデータ変換を簡素化する。35

### 4.2 ストリーム（Stream）とタスク（Task）

ストリームとタスクは、Snowflakeで連続的なデータパイプライン（continuous data pipelines）を構築し、ワークフローを自動化する核心的なオブジェクトである。39

#### 4.2.1 ストリーム (Stream)

ストリームは、元のテーブルに対するDML変更（INSERT、UPDATE、DELETE）を追跡するオブジェクトである。41 ストリームをクエリすると、最後に読み取った時点以降の変更されたデータのみが返されるため、変更データキャプチャ（CDC、Change Data Capture）を実装するのに非常に効果的である。40 ストリームは元のテーブルのデータ自体を保存せず、メタデータ列（

METADATA$ACTION、METADATA$ISUPDATEなど）を通じて変更を記録する。41

#### 4.2.2 タスク (Task)

タスクは、SQL文またはストアドプロシージャを特定のスケジュール（CRONまたはINTERVAL）に従って自動実行するオブジェクトである。42 複数のタスクを依存関係（

AFTER）を持つDAG（Directed Acyclic Graph）として構成し、複雑なデータパイプラインワークフローを自動化できる。42

タスクはユーザーから独立して実行されるため、タスクを作成したユーザーのセッションが終了しても継続して実行される。42

### 4.3 深層分析：ETLからELTへのパラダイムシフト

SnowflakeのSnowpark、Stream、Taskは、データウェアハウジングの伝統的なETL（Extract-Transform-Load）方式からELT（Extract-Load-Transform）方式へのパラダイムシフトを象徴している。1 伝統的なETLは、データを抽出して外部で変換した後、データウェアハウスにロードする方式である。このプロセスでデータが複数のシステムを行き来し、遅延と複雑さを引き起こす。

一方、SnowflakeのELTは、SnowpipeやCOPY INTOを通じてデータを一度Snowflakeにロードした後、Snowflakeの強力なコンピューティングリソース内でSQLまたはSnowparkを使用して変換する。39 このアプローチは、データ移動を最小限に抑え、すべての処理を拡張可能な単一のプラットフォーム内で実行することで、効率とパフォーマンスを最大化する。18

StreamとTaskは、このELTワークフローを継続的に自動化する核心的なツールである。39

このようなパラダイムの変化を理解することは、Snowflakeの哲学を理解することと直結する。試験は、単に各機能の定義を問うだけでなく、これらがどのように有機的に組み合わさってELTパイプラインを構築するかについての理解を要求するだろう。

## 5.0 ドメイン 3.0: パフォーマンスの概念 (15%)

このドメインは、Snowflakeのパフォーマンスを最適化し、コストを効率的に管理する方法を扱う。仮想ウェアハウスの管理、クエリ最適化技法、そして多様なキャッシング層に関する知識が核心である。

### 5.1 仮想ウェアハウスの管理

仮想ウェアハウスは、Snowflakeでクエリを実行するコンピューティングリソースである。44 効率的なウェアハウス管理は、パフォーマンスとコストのバランスを取る上で重要である。

#### 5.1.1 ウェアハウスのサイズ調整 (Sizing)

ウェアハウスは、X-Small（1クレジット）、Small（2クレジット）、Medium（4クレジット）などのTシャツサイズで提供される。各サイズはコンピューティングノードの数を2倍にする。44 適切なウェアハウスサイズの選択は、ワークロードの特性（例：小規模クエリ vs. 大規模データ変換）に応じて決定されるべきである。44 一般的には、

X-Smallウェアハウスで開始し、必要に応じて徐々にサイズを大きくしていくのが良い。45

#### 5.1.2 マルチクラスタリング (Multi-Clustering)

マルチクラスタリングウェアハウスは、同時実行性（concurrency）が高いワークロードに効果的な機能である。この機能はEnterprise Edition以上で提供される。46

Auto-scaleモードでは、クエリの待機列が発生したときに自動的にクラスタ数を増やし、パフォーマンスの低下を防ぐ。Maximizedモードでは、最大クラスタ数が事前に開始され、常に最大のリソースを使用できるようになる。6

#### 5.1.3 自動一時停止/再開 (Auto-suspend/resume)

ウェアハウスを使用しないときに自動的に一時停止してクレジットの消費を防ぎ、クエリが送信されると自動的に再開する。44 この機能は、コストを効率的に管理するのに非常に役立つ。ただし、ウェアハウスが一時停止するとローカルディスクキャッシュが削除されるため、反復的なクエリワークロードの場合は適切な

自動一時停止時間を設定することが重要である。44

### 5.2 クエリパフォーマンスの最適化

#### 5.2.1 マテリアライズドビュー (Materialized View)

マテリアライズドビューは、複雑なクエリの結果を事前に計算して保存するビューである。1 元のテーブルが変更されると自動的に更新され、BIツールなど反復的なクエリワークロードのパフォーマンスを大幅に改善する。1

#### 5.2.2 検索最適化サービス (Search Optimization Service, SOS)

検索最適化サービスは、非常に選択的な（highly selective）クエリ（ポイント検索、部分文字列検索など）のパフォーマンスを画期的に向上させる機能である。47 このサービスは、

検索アクセスパス（Search Access Path）という補助的なデータ構造を生成し、クエリ時にスキャンする必要のあるマイクロパーティションの数を減らす。47 この機能は、

Enterprise Edition以上でのみ利用可能であり、クエリ高速化サービスと連携してパフォーマンスをさらに最適化できる。48

### 5.3 キャッシング層の理解

Snowflakeは、パフォーマンス最適化のために3つの主要なキャッシング層を活用する。49

結果キャッシュ (Result Cache): クラウドサービス層に位置し、以前に実行されたクエリの結果を24時間保存する。3 同じクエリが再度実行されると、ウェアハウスを使用せずに即座にキャッシュされた結果を返す。3

ウェアハウスキャッシュ (Warehouse Cache): コンピューティング層に位置し、仮想ウェアハウスのローカルディスクにクエリ結果をキャッシュする。3 同じウェアハウス内で繰り返されるクエリのパフォーマンスを向上させるが、ウェアハウスが一時停止するとキャッシュは削除される。44

メタデータキャッシュ (Metadata Cache): クラウドサービス層に位置し、マイクロパーティションのメタデータ（値の範囲、プルーニング情報など）をキャッシュして、クエリ計画段階の効率を高める。49

### 5.4 Query Profileの活用

Query Profileは、クエリの実行プロセスを視覚的に分析し、パフォーマンスのボトルネックを特定するために不可欠なツールである。51 実行計画、データスピリング（spilling）など、詳細な情報を提供し、クエリ最適化の方向性を示す。51

プルーニング (Pruning) 分析: Query Profileを通じて、TableScan操作でどれだけのマイクロパーティションがプルーニングされたかを確認できる。52 プルーニング率が低い場合は、
クラスタリングキーを再定義するか、検索最適化サービスを有効にすることを検討する必要がある。

データスピリング (Spilling): クエリ操作がウェアハウスのメモリを超えたときに発生する現象である。44 ローカルディスクやリモートストレージにデータが
スピリングされると、クエリのパフォーマンスが低下する。44
Query Profileでこれを確認でき、これはウェアハウスのサイズ調整の必要性を示唆する。44

### 5.5 深層分析：パフォーマンス最適化の統合的視点

Snowflakeのすべてのパフォーマンス最適化技法は、大きく2つの目標に帰結する：不要なデータスキャンを最小限に抑え、キャッシュの利点を最大化することである。プルーニング、クラスタリング、検索最適化サービスは、すべて不要なマイクロパーティションスキャンを減らすことに焦点を当てている。4 これは、よく整理された書類キャビネットから必要な書類だけを見つけ出すことに例えられる。一方、3段階のキャッシングモデルは、再利用可能なクエリやデータに対してコンピューティングリソースの使用を最小限に抑え、パフォーマンスを向上させる。49

Query Profileは、これら2つの最適化目標が達成されたかどうかを診断するツールである。51 例えば、

Query ProfileのTableScanノードのプルーニング率が低い場合、クラスタリングキーを再定義するか、検索最適化サービスを有効にする必要があるという結論を下すことができる。逆に、ウェアハウスのキャッシュヒット率が低く、データスピリングが発生している場合は、ウェアハウスのサイズ調整が必要であることを意味する。44 Snowflakeのパフォーマンス管理は、各機能の個別の理解を超え、これらがどのように相互補完的に機能するかを把握することにある。

## 6.0 ドメイン 4.0: データのロードとアンロード (10%)

このドメインは、Snowflakeにデータをインポートおよびエクスポートするさまざまな方法を扱う。特に、ステージの概念とCOPY INTO、Snowpipeなどの主要なコマンドの違いを明確に理解する必要がある。

### 6.1 ステージ（Stage）とファイルフォーマット

ステージは、Snowflakeテーブルにデータをロードしたり、テーブルからデータをアンロードしたりする前に、ファイルを一時的に保存する場所である。53

内部ステージと外部ステージに分けられる。53

内部ステージ: Snowflakeの内部に存在し、ユーザーステージ（User Stage）、テーブルステージ（Table Stage）、名前付き内部ステージ（Named Internal Stage）に分かれる。53

外部ステージ: AWS S3、Azure Blob Storage、Google Cloud Storageなどの外部クラウドストレージにあるファイルを参照する。54 外部ステージは、大量の生データファイルを保存する際にストレージコストを削減するのに役立つ。53

### 6.2 データロードとアンロードのベストプラクティス

#### 6.2.1 COPY INTO

COPY INTOは、ステージに保存された1つ以上のファイルからデータを一括（bulk）でロードするために使用される主要なコマンドである。1 また、テーブルのデータを

ステージにアンロードするためにも使用される。1

#### 6.2.2 Snowpipe

Snowpipeは、Snowflakeのサーバーレス（serverless）データロードサービスである。55 新しいファイルが

ステージに到着すると自動的にデータをロードし、連続的なデータパイプラインを構築する。55

COPY INTOがバッチ（batch）方式であるのに対し、Snowpipeはリアルタイムに近いストリーミングローディングに適している。56

#### 6.2.3 PUT/GET

PUTは、ローカルファイルシステムから内部ステージにファイルをアップロードし、GETは内部ステージからローカルファイルシステムにファイルをダウンロードする。16 これらのコマンドは、

SnowSQL CLIでのみ実行可能である点が重要である。16

### 6.3 深層分析：「バッチ」と「ストリーミング」アーキテクチャの選択

Snowflakeのデータロード方法は、単にコマンドの違いを超え、ビジネスのデータ要件に応じて適切なアーキテクチャを選択する重要な決定プロセスである。COPY INTOは、大容量データを決まった時間に一度に処理する伝統的なバッチワークロードに適している。56 例えば、毎晩大量の販売データをロードする必要がある場合、

COPY INTOが効果的だろう。

一方、Snowpipeは、IoTセンサーデータ、アプリケーションログなど、継続的に発生する小規模なファイルを遅延なくロードする必要があるストリーミングワークロードに最適化されている。55 このサービスは、ファイルを自動的に検出し、ロードするサーバーレスアーキテクチャを通じて、データ移動を最小限に抑え、リアルタイムに近い分析を可能にする。55 試験では、単に2つのコマンドの機能を知るだけでなく、どのビジネスシナリオでどの方法を選択すべきかについての理解を要求するだろう。

## 7.0 ドメイン 6.0: データ保護とデータ共有 (10%)

このドメインは、Snowflakeの強力なデータ保護と共有機能を扱う。すべての機能の根底には、「データ複製なしでメタデータを活用する」というSnowflakeの独占的なアーキテクチャ原理が隠されている。

### 7.1 継続的なデータ保護

#### 7.1.1 Time Travel

Time Travelは、データが変更または削除された後も、一定期間、過去の時点のデータをクエリ、複製、または復元できる機能である。24 基本的なデータ保持期間は1日であり、

Enterprise Edition以上では最大90日まで拡張できる。24

Time Travel期間が過ぎると、データはFail-safe段階に移行する。24 この機能は、誤ってデータを削除したり、更新エラーを簡単に回復したりできるようにする。58

#### 7.1.2 Fail-safe

Fail-safeは、Time Travel期間が終了した後に開始される緊急回復期間である。自動的に7日間維持され、この期間中、データはSnowflakeによって回復できるが、ユーザーが直接アクセスすることはできない。

Fail-safeは、データ損失に対する最終的なセーフティネットの役割を果たし、災害復旧などの極端な状況に備える上で重要である。

### 7.2 Zero-Copy Cloning

Zero-Copy Cloningは、データベース、スキーマ、またはテーブルの完全な複製を、物理的なデータをコピーせずに生成する機能である。22 元のデータブロックに対するメタデータポインタのみを生成するため、複製プロセスはほぼ瞬時であり、追加のストレージコストは発生しない。22 複製でデータが変更された場合にのみ、新しいデータブロックが生成される

copy-on-writeメカニズムを使用する。60 この機能は、開発およびテスト用のサンドボックス環境の作成、データサイエンティストの安全なデータ探索、データバックアップおよびバージョン管理など、さまざまなシナリオで活用される。60

### 7.3 Secure Data Sharing

Secure Data Sharingは、Snowflakeアカウント間でデータベースオブジェクト（テーブル、ビューなど）をリアルタイムで共有する機能である。61 データプロバイダー（provider）が

Shareオブジェクトを作成し、コンシューマー（consumer）に提供すると、コンシューマーはこのShareを通じてデータを読み取り専用で即座にアクセスできる。23 実際のデータはコピーも転送もされず、プロバイダーアカウントの元のデータへの参照のみが共有される。23 利点としては、データ複製とETLパイプライン構築の必要性をなくし、プロバイダーは常に最新のデータを共有でき、コンシューマーはストレージコストなしでコンピューティングコストのみで共有データをクエリできる点がある。23

### 7.4 Snowflake MarketplaceとData Exchange

Snowflake MarketplaceとData Exchangeは、Secure Data Sharingに基づいて構築されたデータ共有プラットフォームである。

Snowflake Marketplace: データプロバイダーがキュレーションされたデータ製品（データセット、アプリなど）を無料または有料で販売できる公開プラットフォームである。62 多数のコンシューマーに同時にデータを共有でき、データ販売と収益創出の機会を提供する。63

Data Exchange: 特定のアカウントグループ（例：企業内の部署間）向けの非公開データ共有ハブである。64 プロバイダーは特定のグループメンバーにのみデータを公開し、共有でき、厳格なガバナンス統制を維持できる。65

### 7.5 深層分析：「Zero-Copy」原理が実装するデータエコシステム

Zero-Copy Cloning、Secure Data Sharing、Time Travelは、異なる機能のように見えるが、「物理的なデータコピーなしでメタデータを活用して論理的な機能を実装する」という同じアーキテクチャ原理に基づいている。22

Zero-Copy Cloningは、「内部アカウント」でデータ複製を作成する機能であり、Secure Data Sharingは、「外部アカウント」にデータを共有する機能である。両機能とも、物理的なデータ複製という伝統的な方式の非効率性を根本的に解決する。Time Travelは、このメタデータ管理技術を「データ回復」という別の活用事例に拡張したものである。この関連関係を理解すれば、試験で各機能の詳細な動作原理をより簡単に把握できるだろう。

## 8.0 結論と最終的な学習提案

本レポートは、Snowflake SnowPro Core認定試験の核心概念を、出題比重の高い順に深層分析して提示した。レポートの主要な分析によると、Snowflakeの各機能は独立しておらず、分離型アーキテクチャのような根本的な原理に基づいて相互に接続されている。

アーキテクチャの重要性: すべての概念の根本は、ストレージ、コンピューティング、クラウドサービスの分離型3層アーキテクチャにある。この設計のおかげで、マイクロパーティションベースのプルーニングが可能になり、Time Travel、Zero-Copy Cloning、Secure Data Sharingのようなデータ複製のない高度な機能が実装できる。

パフォーマンスとコストの統合: パフォーマンス最適化は、単にクエリを高速化するだけでなく、Query Profileを通じてパフォーマンスのボトルネック（例：データスピリング）を診断し、ウェアハウスのサイズ調整や検索最適化サービスなどの機能を通じてコスト効率を最大化するプロセスである。

ELTワークフローの理解: Snowpipe、ストリーム、タスクは、データをSnowflake内で変換するELTパイプラインを自動化する核心的なツールである。これは、データ移動を最小限に抑え、拡張性を高めるSnowflakeの根本的な強みである。

セキュリティとガバナンスの結合: Snowflakeのセキュリティモデルは、ロール階層を基本としながらも、オブジェクトタグやSecure Viewなどのガバナンス機能を組み合わせて、詳細なデータ保護を可能にする。

試験準備を超え、このレポートで扱った概念は、Snowflakeをコスト効率よく、安定して運用するために不可欠な実務能力に直結する。試験を準備する受験者は、各概念の定義を暗記するだけでなく、これらがSnowflakeエコシステム内でどのように相互作用するかを深く理解する努力が必要である。